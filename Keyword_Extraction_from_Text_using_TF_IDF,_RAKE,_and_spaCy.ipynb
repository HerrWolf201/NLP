{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrClILoNVf2L+WhoKh1vYj"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Load and Preprocess Text Data**"
      ],
      "metadata": {
        "id": "yb43KZDAqcYz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58bU5hZ0pps_",
        "outputId": "d33a27c2-e965-49c6-d985-c721adf61f0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rake-nltk in /usr/local/lib/python3.11/dist-packages (1.0.6)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from rake-nltk) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (4.67.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import spacy\n",
        "!pip install rake-nltk\n",
        "\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Sample text data\n",
        "data = [\n",
        "    \"Natural language processing is a field of artificial intelligence.\",\n",
        "    \"Keyword extraction helps in identifying the important terms in text.\",\n",
        "    \"SpaCy and NLTK are useful Python libraries for NLP tasks.\",\n",
        "    \"RAKE is a rapid automatic keyword extraction method.\",\n",
        "]\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data, columns=[\"text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **TF-IDF Keyword Extraction**"
      ],
      "metadata": {
        "id": "isOQytGvqoy6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the vectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "# Fit the model and transform the data\n",
        "tfidf_matrix = vectorizer.fit_transform(df['text'])\n",
        "\n",
        "# Get the feature names (words) and corresponding TF-IDF scores\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "scores = tfidf_matrix.sum(axis=0).A1\n",
        "\n",
        "# Combine the words and their scores into a DataFrame\n",
        "tfidf_keywords = pd.DataFrame(zip(feature_names, scores), columns=['keyword', 'score'])\n",
        "\n",
        "# Sort by score in descending order\n",
        "tfidf_keywords = tfidf_keywords.sort_values(by='score', ascending=False)\n",
        "\n",
        "# Display top N keywords (let's say top 5)\n",
        "top_n_tfidf = tfidf_keywords.head(5)\n",
        "print(\"Top N Keywords using TF-IDF:\")\n",
        "print(top_n_tfidf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BqLUAqTqlta",
        "outputId": "f639673f-5654-4233-8d7b-7844f89258ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top N Keywords using TF-IDF:\n",
            "       keyword     score\n",
            "2   extraction  0.659851\n",
            "8      keyword  0.659851\n",
            "18       rapid  0.436719\n",
            "17        rake  0.436719\n",
            "1    automatic  0.436719\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **RAKE Keyword Extraction**"
      ],
      "metadata": {
        "id": "GGnL0eE1snj4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll now use RAKE (Rapid Automatic Keyword Extraction) to extract keywords from the text.\n",
        "\n"
      ],
      "metadata": {
        "id": "akNDeKjgsyeE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rake_nltk import Rake\n",
        "\n",
        "# Initialize RAKE\n",
        "rake = Rake()\n",
        "\n",
        "# Extract keywords for each document\n",
        "rake_keywords = []\n",
        "for text in df['text']:\n",
        "    rake.extract_keywords_from_text(text)\n",
        "    keywords = rake.get_ranked_phrases_with_scores()\n",
        "    rake_keywords.append(keywords)\n",
        "\n",
        "# Display RAKE results\n",
        "print(\"RAKE Keyword Extraction Results:\")\n",
        "for idx, keywords in enumerate(rake_keywords):\n",
        "    print(f\"Document {idx + 1}: {keywords[:5]}\")  # Top 5 keywords per document\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCHvg4xSrano",
        "outputId": "857a0671-77af-4bbb-fd70-0dfb9c65be4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RAKE Keyword Extraction Results:\n",
            "Document 1: [(9.0, 'natural language processing'), (4.0, 'artificial intelligence'), (1.0, 'field')]\n",
            "Document 2: [(9.0, 'keyword extraction helps'), (4.0, 'important terms'), (1.0, 'text'), (1.0, 'identifying')]\n",
            "Document 3: [(9.0, 'useful python libraries'), (4.0, 'nlp tasks'), (1.0, 'spacy'), (1.0, 'nltk')]\n",
            "Document 4: [(25.0, 'rapid automatic keyword extraction method'), (1.0, 'rake')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **spaCy Keyword Extraction (Using Named Entity Recognition)**"
      ],
      "metadata": {
        "id": "d5KvHRcftuYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load spaCy model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Function to extract named entities\n",
        "def extract_spacy_keywords(text):\n",
        "    doc = nlp(text)\n",
        "    entities = [ent.text for ent in doc.ents]\n",
        "    return entities\n",
        "\n",
        "# Apply spaCy NER to each document\n",
        "spacy_keywords = df['text'].apply(extract_spacy_keywords)\n",
        "\n",
        "# Display results\n",
        "print(\"spaCy Named Entity Recognition Results:\")\n",
        "print(spacy_keywords)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7MZBZjctbh3",
        "outputId": "14466406-b557-4ec1-85c6-bf280f3abec3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spaCy Named Entity Recognition Results:\n",
            "0             []\n",
            "1      [Keyword]\n",
            "2    [NLTK, NLP]\n",
            "3             []\n",
            "Name: text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Compare Results**"
      ],
      "metadata": {
        "id": "4JdtfYUpuCgB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we've applied TF-IDF, RAKE, and spaCy for keyword extraction, let's compare the results:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   TF-IDF: Ranks terms based on their importance in the entire corpus.\n",
        "*   RAKE: Extracts keywords by evaluating co-occurrence of words.\n",
        "*   spaCy NER: Extracts named entities, such as people, locations, and organizations.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "swYrUU_ouEgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Comparison of TF-IDF, RAKE, and spaCy results:\")\n",
        "print(\"TF-IDF top N keywords:\")\n",
        "print(top_n_tfidf)\n",
        "print(\"\\nRAKE keywords (top 5 per document):\")\n",
        "for idx, keywords in enumerate(rake_keywords):\n",
        "    print(f\"Document {idx + 1}: {keywords[:5]}\")\n",
        "print(\"\\nspaCy Named Entities:\")\n",
        "print(spacy_keywords)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sfpbm_FFt9ND",
        "outputId": "2ebbce30-d9f1-4b7a-c106-763365fb0227"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparison of TF-IDF, RAKE, and spaCy results:\n",
            "TF-IDF top N keywords:\n",
            "       keyword     score\n",
            "2   extraction  0.659851\n",
            "8      keyword  0.659851\n",
            "18       rapid  0.436719\n",
            "17        rake  0.436719\n",
            "1    automatic  0.436719\n",
            "\n",
            "RAKE keywords (top 5 per document):\n",
            "Document 1: [(9.0, 'natural language processing'), (4.0, 'artificial intelligence'), (1.0, 'field')]\n",
            "Document 2: [(9.0, 'keyword extraction helps'), (4.0, 'important terms'), (1.0, 'text'), (1.0, 'identifying')]\n",
            "Document 3: [(9.0, 'useful python libraries'), (4.0, 'nlp tasks'), (1.0, 'spacy'), (1.0, 'nltk')]\n",
            "Document 4: [(25.0, 'rapid automatic keyword extraction method'), (1.0, 'rake')]\n",
            "\n",
            "spaCy Named Entities:\n",
            "0             []\n",
            "1      [Keyword]\n",
            "2    [NLTK, NLP]\n",
            "3             []\n",
            "Name: text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Final Notes:**\n",
        "*  TF-IDF is great for identifying terms that are important across all documents.\n",
        "*  TF-IDF is great for identifying terms that are important across all documents.\n",
        "*   spaCy works well for named entity recognition but may not capture all keywords, especially non-entity terms.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QTLP0qpTw3Xc"
      }
    }
  ]
}